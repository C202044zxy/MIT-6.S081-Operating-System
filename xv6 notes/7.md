A common approach is to provide each process with the illusion that it has its own virtual CPU by *multiplexing* the processes on to hardware CPUs.

## 7.1 Multiplexing

Xv6 multiplexes by switching each CPU from one process to another in two situations:

- Xv6's `sleep` and `wakeup` mechanism switches when a process waits for device or pipe I/O to complete, or waits for a child to exit, or waits in the `sleep` system call. 
- Xv6 periodically forces a switch to cope with processes that compute for long periods without sleeping. 

## 7.2 Code: Context switching

<img src="picutres\7.png" width = 700>

Figure 7.1 outlines the steps involved in switching from one user process to another:

1. A user-kernel transition (system call or interrupt) to the old process's kernel thread.
2. A context switch to the current CPU's scheduler thread.
3. A context switch to a new process's kernel thread.
4. A trap return to the user-level process.

The function `swtch` performs the saves and restores for a kernel thread switch. It just saves and restores sets of 32 RISC-V registers, called *context*.

`swtch` takes two arguments: `struct context *old` and `struct context *new`. It saves the current registers in `old`, loads registers from `new` and returns. 

`swtch` only saves callee-saved registers. The C compiler generates code in the caller to save caller-saved registers on the stack. For example, it does not save program counter. Instead, `swtch` saves the `ra` register, which holds the return address where `swtch` was called.

When `swtch` returns, it returns to the instructions pointed to by the restored `ra` register. That is, the instruction from which the new thread previously called `swtch`. Additionally, it returns on the new thread's stack.

## 7.3 Code: Scheduling 

The scheduler exists in the form of a special thread per CPU, each running the `scheduler` function. The function is in charge of choosing which thread to run next.

To be concrete, `scheduler` runs a loop, find a process to run, run it until it yields, and repeat. The xv6 code is as follows:

```c++
// Per-CPU process scheduler.
// Each CPU calls scheduler() after setting itself up.
// Scheduler never returns.  It loops, doing:
//  - choose a process to run.
//  - swtch to start running that process.
//  - eventually that process transfers control
//    via swtch back to the scheduler.
void
scheduler(void)
{
  struct proc *p;
  struct cpu *c = mycpu();
  c->proc = 0;
  for(;;){
    // Avoid deadlock by ensuring that devices can interrupt.
    intr_on();
    for(p = proc; p < &proc[NPROC]; p++) {
      acquire(&p->lock);
      if(p->state == RUNNABLE) {
        // Switch to chosen process.  It is the process's job
        // to release its lock and then reacquire it
        // before jumping back to us.
        p->state = RUNNING;
        c->proc = p;
        swtch(&c->context, &p->context);
        // Process is done running for now.
        // It should have changed its p->state before coming back.
        c->proc = 0;
      }
      release(&p->lock);
    }
  }
}

// Switch to scheduler.  Must hold only p->lock
// and have changed proc->state. Saves and restores
// intena because intena is a property of this
// kernel thread, not this CPU. It should
// be proc->intena and proc->noff, but that would
// break in the few places where a lock is held but
// there's no process.
void
sched(void)
{
  int intena;
  struct proc *p = myproc();
  if(!holding(&p->lock))
    panic("sched p->lock");
  if(mycpu()->noff != 1)
    panic("sched locks");
  if(p->state == RUNNING)
    panic("sched running");
  if(intr_get())
    panic("sched interruptible");
  intena = mycpu()->intena;
  swtch(&p->context, &mycpu()->context);
  mycpu()->intena = intena;
}
```

The only place a kernel thread gives up its CPU is in `sched`, and it always switches to the same location in `scheduler`, which (almost) always switches to some kernel thread that previously called `sched`. Therefore, if we print out the line number where xv6 switches thread, we can observe that:

- `swtch(&p->context, &mycpu()->context)` in `sched` switches to `swtch(&c->context, &p->context)` in `scheduler`.
- `swtch(&c->context, &p->context)` in `scheduler` switches to `swtch(&p->context, &mycpu()->context)` in `sched`.

Procedures that intentionally transfer control to each other via thread switch are referred to *coroutines*. `sche` and `scheduler` are coroutines of each other. 

One way to think about the structure of the scheduling code is that it enforces a set of invariants about each process, and holds `p->lock` whenever those invariants are not true. 

Maintaining the invariants is the reason why xv6 often acquires `p->lock` in one thread and releases it in another, for example acquiring in `yield` and releasing in `scheduler`.

## 7.4 Code: mycpu and myproc

Xv6 maintains a `struct cpu` for each CPU, which records the process currently running on that CPU, saved registers for the CPU's scheduler thread, and the count of nested spinlocks needed to manage interrupt disabling. Xv6 ensures that each CPU's hartid is stored in that CPU's `tp` register while in the kernel.

The return values of `cpuid` and `mycpu` are fragile: if the timer were to interrupt and cause the thread to yield and then move to a different CPU, a previously returned value would no longer be correct. To avoid this problem, xv6 requires that caller disables interrupts, and only enable them after they finish using the return values.

The return value of `myproc` is safe to use even if interrupts are enabled: if a timer interrupt moves the calling process to a different CPU, its `struct proc` pointer will stay the same. 

## 7.6 Code: Sleep and wakeup

The basic idea is to have `sleep` mark the current process as `SLEEPING` and then call `sched` to release the CPU. `wakeup` looks for a process sleeping on the given wait channel and marks it as `RUNNABLE`.

```c
// Atomically release lock and sleep on chan.
// Reacquires lock when awakened.
void
sleep(void *chan, struct spinlock *lk)
{
  struct proc *p = myproc();
  // Must acquire p->lock in order to
  // change p->state and then call sched.
  // Once we hold p->lock, we can be
  // guaranteed that we won't miss any wakeup
  // (wakeup locks p->lock),
  // so it's okay to release lk.
  acquire(&p->lock);  //DOC: sleeplock1
  release(lk);
  // Go to sleep.
  p->chan = chan;
  p->state = SLEEPING;
  sched();
  // Tidy up.
  p->chan = 0;
  // Reacquire original lock.
  release(&p->lock);
  acquire(lk);
}

// Wake up all processes sleeping on chan.
// Must be called without any p->lock.
void
wakeup(void *chan)
{
  struct proc *p;
  for(p = proc; p < &proc[NPROC]; p++) {
    if(p != myproc()){
      acquire(&p->lock);
      if(p->state == SLEEPING && p->chan == chan) {
        p->state = RUNNABLE;
      }
      release(&p->lock);
    }
  }
}
```

It is sometimes the case that multiple processes are sleeping on the same channel. For example, more than one process reading from a pipe. A single call to `wakeup` will wake them all up. One of them will acquire the lock that `sleep` was called with. Others  find that the wakeup was spurious and sleep again. 

## 7.7 Code: Pipes

Bytes written to one end of a pipe are copied to an in-kernel buffer and then can be read from the other end of the pipe. The buffer wraps around: the next byte written after `buf[PIPESIZE - 1]` is `buf[0]`.

If we are writing into the buffer and the buffer fills, `pipewrite` calls `wakeup` to alert any sleeping readers to the fact that there is data waiting in the buffer and then sleeps on `&pi->nwrite` to wait for a reader to take some bytes out of the buffer.

The pipe code uses separate sleep channels for reader and writer.

## 7.8 Code: Wait, exit, and kill

Child process calls `exit` and changes to `ZOMBIE` state. When parent's `wait` notices it, `wait` will changes the child's state to `UNUSED`, copies the child's exit status, and returns the child's process ID to the parent. 

`Exit` records the exit status, free some resources, calls `reparent` to give its children to the `init` process, wakes up the parent in case it is in `wait`, marks the caller as a zombie, and permanently yields CPU.

While `exit` allows a process to terminate itself, `kill` lets one process request another to terminate. `kill` does very little: it just sets the victim's `p->killed` and if it is sleeping, wake it up.

