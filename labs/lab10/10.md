In `proc.h`, define a structure corresponding to the VMA (virtual memory area). Each process will maintain a list of VMA. 

The VMA is located at `MAXVA/2` and can grow up to `MAXVA`. 

```c
// proc.h
#define NVMA 16
#define VMASTART (MAXVA / 2)

struct vma {
  int use;
  uint64 start;
  uint64 end;
  int perm;
  int flag;
  struct file* file;
  struct vma* next;

  struct spinlock lock;
};

struct proc {
	...
  struct vma* vma;
	...
}
```

`mmap` is no more than allocate an instance of VMA. Note that the start position and length is guaranteed to be page-aligned.

```c
// sysfile.c
uint64 sys_mmap(void) {
  uint64 addr, length;
  int prot, flag, fd;
  uint64 offset;
  if (argaddr(0, &addr) < 0 || argaddr(1, &length) < 0
    || argint(2, &prot) < 0 || argint(3, &flag) < 0 
    || argint(4, &fd) < 0 || argaddr(5, &offset) < 0) {
    return -1;
  }
  
  int perm = PTE_U;
  struct proc* p = myproc();
  struct vma* v = vmaalloc();
  struct file* f = p->ofile[fd];
  if (prot & PROT_READ) {
    if (!f->readable) { return -1; }
    perm |= PTE_R;
  }
  if (prot & PROT_WRITE) {
    if (!f->writable && flag == MAP_SHARED) { return -1; }
    perm |= PTE_W;
  }

  // initialize the VMA
  v->perm = perm;
  v->flag = flag;
  v->file = f;
  // increase file's reference count
  filedup(f);
  
  // page-aligned VMA [start, end)
  if (p->vma == 0) {
    v->start = VMASTART;
    v->end = v->start + length;
    p->vma = v;
  } else {
    v->start = PGROUNDUP(p->vma->end);
    v->end = v->start + length;
    v->next = p->vma;
    p->vma = v;
  }

  return v->start;
}
```

When page fault occurs, we should allocate a new physical page, copy the file block into the physical page and establish mapping in virtual memory.

```c
// trap.c
int vmahandler(int scause, uint64 va) {
  va = PGROUNDDOWN(va);
  struct proc* p = myproc();
  struct vma* v = p->vma;
  while (v) {
    if (v->start <= va && va < v->end) {
      // page fault occurs in v
      break;
    }
    v = v->next;
  }
  if (!v) { return -1; }
  if (scause == 13 && !(v->perm & PTE_R)) { return -1; }
  if (scause == 15 && !(v->perm & PTE_W)) { return -1; }

  uint64 mem = (uint64)kalloc();
  if (mem == 0) { return -1; }
  memset((void*)mem, 0, PGSIZE);
  if (mappages(p->pagetable, va, PGSIZE, mem, v->perm) < 0) {
    kfree((void*)mem);
    return -1;
  }
  // read file into the page
  struct file* f = v->file;
  ilock(f->ip);
  readi(f->ip, 0, mem, va - v->start, PGSIZE);
  iunlock(f->ip);

  return 0;
}
```

`munmap` find the VMA for the address range and write back the pages that have been modified. This can be achieved by walking through the page table and find the corresponding PTE. If such PTE is valid, it should be written back to file. Otherwise the user process has never fetched the PTE and we can just ignore it.

If `munmap` covers the whole VMA, the entry should be removed from the linked list of the process.

```c
uint64 sys_munmap(void) {
  uint64 addr, length;
  if (argaddr(0, &addr) < 0 || argaddr(1, &length) < 0) {
    return -1;
  }

  struct proc* p = myproc();
  struct vma* v = p->vma;
  struct vma* pre = 0;
  while (v) {
    if (v->start <= addr && addr < v->end) {
      break;
    }
    pre = v;
    v = v->next;
  }
  if (!v) { return -1; }

  // assume addr and length is page-aligned
  // search for every pte in the interval
  for (uint64 va = addr; va < addr + length; va += PGSIZE) {
    pte_t* pte = walk(p->pagetable, va, 0);
    // PTE not fetched. Just ignore
    if (*pte == 0) { continue; }
    if ((*pte & PTE_W) && v->flag == MAP_SHARED) {
      // write back
      filewrite(v->file, va, PGSIZE);
    }
    // unmap the PTE
    uvmunmap(p->pagetable, va, 1, 1);
  }
  if (v->start == addr && v->end == addr + length) {
    // cover the whole area, release the VMA
    if (v == p->vma) {
      p->vma = v->next;
    } else if (pre) {
      pre->next = v->next;
    }
    fileclose(v->file);
    acquire(&(v->lock));
    v->use = 0;
    v->start = v->end = 0;
    v->flag = v->perm = 0;
    v->file = v->next = 0;
    release(&(v->lock));

  } else if (v->start == addr) {
    // free from start
    v->start += length;
  } else {
    // free from end
    v->end -= length;
  }
  return 0;
}
```

`fork` copies the VMA entries from father process to child process.

`exit` unmaps the process's mapped regions as if `munmap` had been called. 

```c
int
fork(void) {
	...
	// Copy VMA from parent to child
  struct vma* pv = p->vma;
  while (pv) {
    struct vma* v = vmaalloc();
    v->start = pv->start;
    v->end = pv->end;
    v->flag = pv->flag;
    v->perm = pv->perm;
    filedup(pv->file);
    v->file = pv->file;
    v->next = np->vma;
    np->vma = v;

    // move to the next
    pv = pv->next;
  }
  ...
}

void
exit(int status) {
  ... 
  // release all VMA
  struct vma* v = p->vma;
  while (v) {
    struct vma* next = v->next;

    for (uint64 va = v->start; va < v->end; va += PGSIZE) {
      pte_t* pte = walk(p->pagetable, va, 0);
      if (*pte == 0) { continue; }
      if ((*pte & PTE_W) && v->flag == MAP_SHARED) {
        filewrite(v->file, va, PGSIZE);
      }
      uvmunmap(p->pagetable, va, 1, 1);
    }

    fileclose(v->file);
    acquire(&(v->lock));
    v->use = 0;
    v->start = v->end = 0;
    v->flag = v->perm = 0;
    v->file = v->next = 0;
    release(&(v->lock));
    
    v = next;
  }
  p->vma = 0;
  ...
}
```

